import os
from openai import OpenAI

def split_text_into_chunks(text, chunk_size=None, line_count=None):
    """
    Split a long text into smaller chunks for processing.
    Either by character count or by number of lines.
    """
    # Split text into lines
    lines = text.split('\n')
    
    # If no chunk specifications are provided, return as single chunk
    if not chunk_size and not line_count:
        return [text]
    
    # If line count is specified, split by number of lines
    if line_count:
        chunks = []
        total_lines = len(lines)
        
        for i in range(0, total_lines, line_count):
            chunk_lines = lines[i:i + line_count]
            chunks.append('\n'.join(chunk_lines))
        
        return chunks
    
    # Otherwise split by character count
    if chunk_size:
        # If text is shorter than chunk_size, return it as a single chunk
        if len(text) <= chunk_size:
            return [text]
        
        chunks = []
        
        # Try to split on paragraph breaks
        paragraphs = text.split('\n\n')
        current_chunk = ""
        
        for paragraph in paragraphs:
            # If adding this paragraph exceeds chunk size and we already have content
            if len(current_chunk) + len(paragraph) > chunk_size and current_chunk:
                chunks.append(current_chunk)
                current_chunk = paragraph
            # Otherwise, add to current chunk
            else:
                if current_chunk:
                    current_chunk += "\n\n" + paragraph
                else:
                    current_chunk = paragraph
        
        # Add the last chunk if it has content
        if current_chunk:
            chunks.append(current_chunk)
        
        # If we have extremely long paragraphs, we might need to split them further
        final_chunks = []
        for chunk in chunks:
            if len(chunk) <= chunk_size:
                final_chunks.append(chunk)
            else:
                # Split by sentences (roughly)
                sentences = chunk.replace('. ', '.\n').split('\n')
                sub_chunk = ""
                
                for sentence in sentences:
                    if len(sub_chunk) + len(sentence) > chunk_size and sub_chunk:
                        final_chunks.append(sub_chunk)
                        sub_chunk = sentence
                    else:
                        if sub_chunk:
                            sub_chunk += " " + sentence
                        else:
                            sub_chunk = sentence
                
                if sub_chunk:
                    final_chunks.append(sub_chunk)
        
        return final_chunks
    
    return [text]

def process_text_with_chatgpt(text, api_key=None, model="gpt-4o"):
    """
    Process Russian text through ChatGPT to enhance readability
    while preserving content.
    """
    # The newest OpenAI model is "gpt-4o" which was released May 13, 2024.
    # do not change this unless explicitly requested by the user
    
    # Use environment variable if api_key is not provided
    if not api_key:
        # Try to get API key from different environment variables
        api_key = os.environ.get("OPENAI_KEY") or os.environ.get("OPENAI_API_KEY")
        
    if not api_key:
        raise Exception("No OpenAI API key found. Please check your Secrets or .env file.")
        
    client = OpenAI(api_key=api_key)
    
    # The prompt provided by the user
    prompt = """
    –°–æ—Ö—Ä–∞–Ω–∏ –≤–µ—Å—å —Ç–µ–∫—Å—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é, –∏—Å–ø—Ä–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –ø—Ä–∏–º–µ—Ä–æ–≤, –ø–æ—è—Å–Ω–µ–Ω–∏–π –∏–ª–∏ —Ç–µ—Ä–º–∏–Ω–æ–≤.
    –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—é:
    –†–∞–∑–±–µ–π —Ç–µ–∫—Å—Ç –Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –±–ª–æ–∫–∏ —Å –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏.
    –ü–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è –∏ –ø—Ä–∏–º–µ—Ä—ã –æ—Ñ–æ—Ä–º–ª—è–π –≤ –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–µ —Å–ø–∏—Å–∫–∏.
    –í—Å–µ —Ä–æ–ª–∏, —Ç–µ—Ä–º–∏–Ω—ã –∏ –∫–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏ –¥–æ–ª–∂–Ω—ã –æ—Å—Ç–∞—Ç—å—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
    –ü–æ–¥–∞—á–∞ —Ç–µ–∫—Å—Ç–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ —É—á–µ–±–Ω–æ–π –∫–Ω–∏–≥–∏: —á–∏—Å—Ç–æ, —Ç–µ–∑–∏—Å–Ω–æ, –ª–æ–≥–∏—á–Ω–æ, –ª–µ–≥–∫–æ —á–∏—Ç–∞–µ–º–æ.
    –°–æ—Ö—Ä–∞–Ω—è–π –∞–≤—Ç–æ—Ä—Å–∫–∏–π —Å—Ç–∏–ª—å –∏ –∏–Ω—Ç–æ–Ω–∞—Ü–∏—é ‚Äî –Ω–µ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π.
    –ù–µ —É–ø—Ä–æ—â–∞–π –∏ –Ω–µ –æ–±–æ–±—â–∞–π —Ç–µ–∫—Å—Ç ‚Äî –≤—Å–µ –¥–µ—Ç–∞–ª–∏ –∏ –Ω—é–∞–Ω—Å—ã –≤–∞–∂–Ω—ã.
    ‚ö° –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –¥–ª—è –æ–¥–Ω–æ–≥–æ –±–ª–æ–∫–∞ ‚Äî —É–≤–µ–¥–æ–º—å –æ–± —ç—Ç–æ–º.
    ‚úèÔ∏è –û—Ç–≤–µ—á–∞–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Ä–∞–∑–º–µ—Ç–∫–∏: –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏, –±–ª–æ–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
    üéØ –¶–µ–ª—å: —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω —á–∏—Ç–∞—Ç—å—Å—è –∫–∞–∫ –≥–ª–∞–≤–∞ —É—á–µ–±–Ω–æ–π –∫–Ω–∏–≥–∏ ‚Äî —è—Å–Ω–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –Ω–æ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∂–∏–≤–æ–≥–æ –∞–≤—Ç–æ—Ä—Å–∫–æ–≥–æ —Ç–æ–Ω–∞
    
    –û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown.
    
    –í–æ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:
    
    """
    
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "You are a Russian language expert who improves transcribed text while preserving its content."},
                {"role": "user", "content": prompt + text}
            ],
            temperature=0.3,  # Lower temperature for more consistent results
            max_tokens=4096,  # Adjust as needed
        )
        
        # Extract the improved text from the response
        improved_text = response.choices[0].message.content
        return improved_text
    
    except Exception as e:
        raise Exception(f"Error processing text with ChatGPT: {str(e)}")
